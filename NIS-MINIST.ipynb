{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'criterion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 109\u001b[0m\n\u001b[1;32m    107\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m    108\u001b[0m target_onehot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], output_dim)\u001b[38;5;241m.\u001b[39mscatter_(\u001b[38;5;241m1\u001b[39m, target\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m(output, target_onehot)\n\u001b[1;32m    110\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    111\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'criterion' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 超参数设置\n",
    "epochs = 500\n",
    "batch_size = 64\n",
    "input_dim = 25\n",
    "output_dim = 5\n",
    "layer_dims = [25, 6, 6, 6, 5]\n",
    "colors = ['#1f77b4', '#ff7f0e', '#d62728', '#2ca02c']  # 蓝、橙、红、绿\n",
    "num_runs = 3  # 运行次数\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((5, 5)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 归一化到[-1,1]\n",
    "])\n",
    "\n",
    "# 加载MNIST数据集（仅取0-4）\n",
    "train_dataset = datasets.MNIST(root='/tmp/data', train=True, download=True, transform=transform)\n",
    "train_mask = (train_dataset.targets < 5)\n",
    "train_dataset.data = train_dataset.data[train_mask]\n",
    "train_dataset.targets = train_dataset.targets[train_mask]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 定义神经网络\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(layer_dims[0], layer_dims[1]), nn.Sigmoid(),\n",
    "            nn.Linear(layer_dims[1], layer_dims[2]), nn.Sigmoid(),\n",
    "            nn.Linear(layer_dims[2], layer_dims[3]), nn.Sigmoid(),\n",
    "            nn.Linear(layer_dims[3], layer_dims[4])\n",
    "        )\n",
    "        \n",
    "        # 注册钩子捕获中间层输出\n",
    "        self.activations = {}\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                self.activations[name] = output.detach()\n",
    "            return hook\n",
    "        \n",
    "        self.layers[1].register_forward_hook(get_activation('T1'))\n",
    "        self.layers[3].register_forward_hook(get_activation('T2'))\n",
    "        self.layers[5].register_forward_hook(get_activation('T3'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# EI计算函数\n",
    "def calculate_ei(input_dim, output_dim, layer_func, n_samples=200):\n",
    "    # 蒙特卡洛采样\n",
    "    X = torch.rand(n_samples, input_dim) * 2 - 1  # 均匀分布[-1,1]\n",
    "    \n",
    "    log_dets = []\n",
    "    for x in X:\n",
    "        x = x.unsqueeze(0)  # 增加 batch 维度\n",
    "        x.requires_grad_(True)  # 启用梯度计算\n",
    "        \n",
    "        # 计算输出\n",
    "        y = layer_func(x)\n",
    "        \n",
    "        # 计算雅可比矩阵\n",
    "        jacobian = torch.zeros((output_dim, input_dim))\n",
    "        for i in range(output_dim):\n",
    "            grad = torch.autograd.grad(y[0, i], x, retain_graph=True)[0]\n",
    "            jacobian[i] = grad.squeeze(0)  # 去除 batch 维度\n",
    "        \n",
    "        # 处理非方阵：J @ J^T 的行列式\n",
    "        det = torch.det(jacobian @ jacobian.T)\n",
    "        log_dets.append(torch.log(torch.abs(det) + 1e-8).item())\n",
    "    \n",
    "    expectation = np.mean(log_dets)\n",
    "    \n",
    "    # 噪声估计（使用训练数据）\n",
    "    X_val = torch.rand(1000, input_dim) * 2 - 1\n",
    "    y_pred = layer_func(X_val)\n",
    "    rmse = torch.sqrt(torch.mean((y_pred - y_pred.mean(dim=0))**2, dim=0))\n",
    "    sigma_term = 0.5 * torch.sum(torch.log(rmse**2 + 1e-8))\n",
    "    \n",
    "    # NIS公式\n",
    "    ei = input_dim * np.log(2) - 0.5 * output_dim * (1 + np.log(2 * np.pi)) - sigma_term + expectation\n",
    "    return ei.item()\n",
    "\n",
    "# 多次运行实验\n",
    "all_ei_history = []\n",
    "for run in range(num_runs):\n",
    "    # 初始化模型\n",
    "    model = Net()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # 训练模型并计算EI\n",
    "    ei_history = {'X-T1': [], 'T1-T2': [], 'T2-T3': [], 'T3-Y': []}\n",
    "    for epoch in range(epochs):\n",
    "        # 训练步骤\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            target_onehot = torch.zeros(output.shape[0], output_dim).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "            loss = criterion(output, target_onehot)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # 每50个epoch计算EI\n",
    "        if epoch % 50 == 0 or epoch == epochs-1:\n",
    "            model.eval()\n",
    "            ei_history['X-T1'].append(calculate_ei(layer_dims[0], layer_dims[1], lambda x: model.layers[1](x)))\n",
    "            ei_history['T1-T2'].append(calculate_ei(layer_dims[1], layer_dims[2], lambda x: model.layers[3](x)))\n",
    "            ei_history['T2-T3'].append(calculate_ei(layer_dims[2], layer_dims[3], lambda x: model.layers[5](x)))\n",
    "            ei_history['T3-Y'].append(calculate_ei(layer_dims[3], layer_dims[4], lambda x: model.layers[7](x)))\n",
    "    \n",
    "    # 保存每次运行的结果\n",
    "    all_ei_history.append(ei_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_runs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 可视化多次运行结果\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX-T1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT1-T2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT2-T3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT3-Y\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mnum_runs\u001b[49m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;66;03m# 只在第一次运行时添加标签，其他运行不添加（避免重复图例）\u001b[39;00m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      6\u001b[0m             plt\u001b[38;5;241m.\u001b[39mplot(x_ticks, all_ei_history[run][label], \n\u001b[1;32m      7\u001b[0m                     color\u001b[38;5;241m=\u001b[39mcolors[idx], \n\u001b[1;32m      8\u001b[0m                     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.2\u001b[39m \u001b[38;5;241m*\u001b[39m run, \n\u001b[1;32m      9\u001b[0m                     linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \n\u001b[1;32m     10\u001b[0m                     label\u001b[38;5;241m=\u001b[39mlabel)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_runs' is not defined"
     ]
    }
   ],
   "source": [
    "# 可视化多次运行结果\n",
    "for idx, label in enumerate(['X-T1', 'T1-T2', 'T2-T3', 'T3-Y']):\n",
    "    for run in range(num_runs):\n",
    "        # 只在第一次运行时添加标签，其他运行不添加（避免重复图例）\n",
    "        if run == 0:\n",
    "            plt.plot(x_ticks, all_ei_history[run][label], \n",
    "                    color=colors[idx], \n",
    "                    alpha=0.3 + 0.2 * run, \n",
    "                    linewidth=2, \n",
    "                    label=label)\n",
    "        else:\n",
    "            plt.plot(x_ticks, all_ei_history[run][label],\n",
    "                    color=colors[idx],\n",
    "                    alpha=0.3 + 0.2 * run,\n",
    "                    linewidth=2)\n",
    "plt.xlabel('Training Epoch', fontsize=12)\n",
    "plt.ylabel('EI (bits)', fontsize=12)\n",
    "plt.title('MNIST Layer-wise Effective Information Dynamics', fontsize=14)\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.xlim(0, epochs)\n",
    "plt.ylim(-20, 40)  # 纵轴区间\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (R)",
   "language": "python",
   "name": "myrkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
